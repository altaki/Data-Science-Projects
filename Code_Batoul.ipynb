{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/altaki/Data-Science-Projects/blob/main/Code_Batoul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VvOdFIJM6Ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elCqkh58M6Cg",
        "outputId": "c3bb9cd8-b2c1-449c-ba3c-f16ce411cda3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN counts in the dataset:\n",
            "N°Obs                                                        0\n",
            "2. 1. Avez-vous déjà vu une campagne de produit partage ?    0\n",
            "4. 3. Avez-vous déjà acheté un produit partage ?             0\n",
            "6. Les produits de Volvic me rassurent                       0\n",
            "7. J’ai confiance dans la qualité des produits de Volvic     0\n",
            "                                                            ..\n",
            "Genre                                                        0\n",
            "Situation_familiale                                          0\n",
            "Niveau_etude                                                 0\n",
            "Profession                                                   0\n",
            "Revenu_net_mensuel                                           0\n",
            "Length: 76, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load the data from the Excel sheet\n",
        "survey_data = pd.read_excel('Ba.xlsx')\n",
        "\n",
        "# Check for NaN values in the dataset\n",
        "nan_counts = survey_data.isna().sum()\n",
        "print(\"NaN counts in the dataset:\")\n",
        "print(nan_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay03bXDqM6Cg"
      },
      "outputs": [],
      "source": [
        "# Handle NaN values by imputing with the mean\n",
        "if nan_counts.sum() > 0:\n",
        "    survey_data = survey_data.fillna(survey_data.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the demographic columns\n",
        "demographic_columns = ['Genre', 'Profession', 'Situation_familiale', 'Age', 'Niveau_etude']\n",
        "\n",
        "# Identify the question columns\n",
        "question_columns = [col for col in survey_data.columns if col not in demographic_columns]\n",
        "\n",
        "# Separate the features and targets\n",
        "X = survey_data[demographic_columns]\n",
        "y = survey_data[question_columns]\n",
        "\n",
        "# Initialize and train a Random Forest regressor on all features\n",
        "regressor = RandomForestRegressor()\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# Number of new individuals to generate\n",
        "new_individuals_count = 300"
      ],
      "metadata": {
        "id": "T847tSPZUROa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNOMHCmXM6Ch"
      },
      "outputs": [],
      "source": [
        "# Define quotas for demographic features only\n",
        "quotas = {\n",
        "    'Age': {1: 0.08, 2: 0.12, 3: 0.12, 4: 0.13, 5: 0.13, 6: 0.17},\n",
        "    'Genre': {1: 0.48, 2: 0.52},  # 1: Male, 2: Female\n",
        "    'Situation_familiale': {1: 0.4, 2: 0.4, 3: 0.2, 4: 0.0},\n",
        "    'Niveau_etude': {1: 0.0, 2: 0.0, 3: 0.2, 4: 0.23, 5: 0.27, 6: 0.3},\n",
        "    'Profession': {1: 0.18, 2: 0.12, 3: 0.13, 4: 0.0, 5: 0.15, 6: 0.25, 7: 0.0, 8: 0.12, 9: 0.05}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4WXoIHgk85l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate new individuals with specified quotas\n",
        "def generate_new_individuals(quotas, total_count):\n",
        "    new_data = {column: [] for column in quotas.keys()}\n",
        "\n",
        "    for column, column_quotas in quotas.items():\n",
        "        remaining_count = total_count\n",
        "        category_counts = []\n",
        "\n",
        "        for category, proportion in column_quotas.items():\n",
        "            count = int(total_count * proportion)\n",
        "            category_counts.append(count)\n",
        "            remaining_count -= count\n",
        "\n",
        "        # Adjust the last category to ensure the total count is exactly total_count\n",
        "        if remaining_count != 0:\n",
        "            category_counts[-1] += remaining_count\n",
        "\n",
        "        for i, (category, _) in enumerate(column_quotas.items()):\n",
        "            new_data[column].extend([category] * category_counts[i])\n",
        "\n",
        "    # Shuffle the new data to ensure random distribution\n",
        "    for column in new_data:\n",
        "        np.random.shuffle(new_data[column])\n",
        "\n",
        "    return pd.DataFrame(new_data)"
      ],
      "metadata": {
        "id": "wWJIhKx6cDRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the new individuals based on quotas\n",
        "new_individuals_demographics = generate_new_individuals(quotas, new_individuals_count)"
      ],
      "metadata": {
        "id": "q8L7UqbSjofg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the new individuals based on quotas\n",
        "new_individuals_demographics = generate_new_individuals(quotas, new_individuals_count)\n",
        "\n",
        "# Generate random responses for non-demographic questions\n",
        "random_responses = np.random.randint(1, 6, size=(new_individuals_count, len(question_columns)))\n",
        "\n",
        "# Create a DataFrame for new individuals with demographic data and random question responses\n",
        "new_individuals = pd.concat([new_individuals_demographics.reset_index(drop=True),\n",
        "                             pd.DataFrame(random_responses, columns=question_columns)], axis=1)\n",
        "\n",
        "# Predict final answers for the survey questions using the trained model\n",
        "predicted_answers = regressor.predict(new_individuals[demographic_columns])\n",
        "new_individuals[question_columns] = predicted_answers.astype(int)\n",
        "\n",
        "# Concatenate the original data and new individuals\n",
        "combined_data = pd.concat([survey_data, new_individuals], ignore_index=True)\n",
        "\n",
        "# Sort the combined data by index\n",
        "combined_data_sorted = combined_data.sort_index()\n",
        "\n",
        "# Export the sorted combined data to an Excel sheet\n",
        "combined_data_sorted.to_excel('combined_data_sorted.xlsx', index=False)"
      ],
      "metadata": {
        "id": "G0_KghAoO1zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_sorted.shape"
      ],
      "metadata": {
        "id": "ZJz-2wzAbGKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation between features\n",
        "To identify which variables or features are correlated with each other, especially in a large dataset with many questions, you can calculate the correlation matrix and then filter it to find pairs of variables with high correlation values. This can be done efficiently using a for loop or by leveraging pandas' capabilities to filter and sort the correlation matrix.\n",
        "\n",
        "Here's how you can achieve this:\n",
        "\n",
        "Calculate the correlation matrix.\n",
        "\n",
        "Unstack the matrix to turn it into a long format.\n",
        "Filter the pairs to find those with high correlation values.\n",
        "Optionally, visualize the correlations for better understanding.\n",
        "Below is the Python code to perform these steps:"
      ],
      "metadata": {
        "id": "UftAraMebO0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = combined_data_sorted"
      ],
      "metadata": {
        "id": "dNmGgqB2bY0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Unstack the correlation matrix to turn it into a long format\n",
        "corr_pairs = corr_matrix.unstack()\n",
        "\n",
        "# Convert to a DataFrame\n",
        "corr_pairs = pd.DataFrame(corr_pairs, columns=['correlation'])\n",
        "\n",
        "# Reset index for easier filtering\n",
        "corr_pairs.reset_index(inplace=True)\n",
        "corr_pairs.columns = ['Feature1', 'Feature2', 'correlation']\n",
        "\n",
        "# Remove self-correlations by filtering out pairs where Feature1 == Feature2\n",
        "corr_pairs = corr_pairs[corr_pairs['Feature1'] != corr_pairs['Feature2']]\n",
        "\n",
        "# Find highly correlated pairs (e.g., correlation > 0.8 or correlation < -0.8)\n",
        "high_corr_pairs = corr_pairs[(corr_pairs['correlation'] > 0.8) | (corr_pairs['correlation'] < -0.8)]\n",
        "\n",
        "# Sort by correlation value\n",
        "high_corr_pairs = high_corr_pairs.sort_values(by='correlation', ascending=False)\n",
        "\n",
        "# Print the highly correlated pairs\n",
        "print(\"Highly correlated pairs:\")\n",
        "print(high_corr_pairs)"
      ],
      "metadata": {
        "id": "Lc6fR2GWbGwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv0jwNhXM6Ck",
        "outputId": "e1535def-4c41-4777-b424-d142597a5fc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(450, 76)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YhNb_G9Uph7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}